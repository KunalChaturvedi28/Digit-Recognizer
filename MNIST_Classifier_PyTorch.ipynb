{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \"\"\"docstring for CNNModel\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # For valid padding -> padding = 0  and change sizes \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.cnn2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #Max/Avg  Pool 1\n",
    "        self.pool1= nn.MaxPool2d(kernel_size=2)\n",
    "        #self.pool1= nn.AvgPool2d(kernel_size=2)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=8 , out_channels=16, kernel_size=5,stride=1,padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.cnn4 = nn.Conv2d(in_channels=16 , out_channels=32, kernel_size=5,stride=1,padding=2)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        #Max/Avg Pool 2\n",
    "        self.pool2= nn.MaxPool2d(kernel_size=2)\n",
    "        #self.pool2= nn.AvgPool2d(kernel_size=2)\n",
    "        #Fully connected 1\n",
    "        self.fc1 = nn.Linear(32*7*7,1000)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.cnn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.cnn4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.pool2(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',train=True,transform = transforms.ToTensor(),download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform = transforms.ToTensor())\n",
    "batch_size = 128\n",
    "n_iters = 4300\n",
    "num_epochs = n_iters/(len(train_dataset)/batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate=0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make load_model true if pre-trained model is present\n",
    "load_model=True\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('CNN_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  500  || Loss =  2.298454761505127\n",
      "Iteration =  1000  || Loss =  2.286841869354248\n",
      "Iteration =  1500  || Loss =  0.2775621712207794\n",
      "Iteration =  2000  || Loss =  0.211588054895401\n",
      "Iteration =  2500  || Loss =  0.08199624717235565\n",
      "Iteration =  3000  || Loss =  0.08795986324548721\n",
      "Iteration =  3500  || Loss =  0.03779427707195282\n",
      "Iteration =  4000  || Loss =  0.033981192857027054\n"
     ]
    }
   ],
   "source": [
    "train_model=True\n",
    "if train_model is True:\n",
    "        iter = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for i,(images,labels) in enumerate(train_loader):\n",
    "                if torch.cuda.is_available():\n",
    "                    images=Variable(images.cuda())\n",
    "                    labels= Variable(labels.cuda())\n",
    "                else:\n",
    "                    images=Variable(images)\n",
    "                    labels= Variable(labels)\n",
    "                optimizer.zero_grad()\n",
    "                outputs=model(images)\n",
    "                loss = criterion(outputs,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                iter+=1\n",
    "                if iter%500==0:\n",
    "                    print('Iteration = ',iter,' || Loss = ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  4221  || Loss =  0.050962332636117935  || Accuracy =  98.12\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "for images,labels in test_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        images = Variable(images.cuda())\n",
    "    else:\n",
    "        images = Variable(images)\n",
    "    outputs=model(images)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    total = total + labels.size(0)\n",
    "    if torch.cuda.is_available():\n",
    "        correct = correct + (predicted.cpu()==labels.cpu()).sum()\n",
    "    else:\n",
    "        correct = correct + (predicted==labels).sum()\n",
    "accuracy = 100 * float(correct)/float(total)\n",
    "print('Iteration = ',iter,' || Loss = ', loss.item(),' || Test set Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model is True:\n",
    "    torch.save(model.state_dict(), 'CNN_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
